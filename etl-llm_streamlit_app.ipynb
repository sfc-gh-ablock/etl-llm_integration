{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "2mc4a263bazfd4assbiv",
   "authorId": "1134732619951",
   "authorName": "ABLOCK",
   "authorEmail": "andy.block@snowflake.com",
   "sessionId": "f5dba4da-7311-4387-9e23-4e4667171dda",
   "lastEditTime": 1740627435725
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "source": "import streamlit as st\nimport pandas as pd\nimport re\nfrom snowflake.snowpark.context import get_active_session\nimport time\nfrom collections import defaultdict\n\nst.set_page_config(layout=\"wide\")\n\n\n# Initialize session\nsession = get_active_session()\n\n\n# Database configurations\nDATABASE = session.sql('select current_database()').collect()[0][0]\nROLE = session.sql('select CURRENT_ROLE()').collect()[0][0]\n\nif ROLE == 'ACCOUNTADMIN':\n    ROLE = 'ROLE100'\n\nROLE_NUM = ROLE.split('ROLE')[1]\nSCHEMA = f'SCHEMA{ROLE_NUM}'\nSCHEMA_BASELINE_TABLE = f'{DATABASE}.{SCHEMA}.SCHEMA_BASELINE'\nSCHEMA_CHANGE_LOG = f'{DATABASE}.{SCHEMA}.SCHEMA_CHANGE_LOG'\nTABLE_NAME = 'TABLE_NAME'\nSOURCE_OBJECT_NAME = 'SOURCE_OBJECT_NAME'\nDISTANCE = 'DISTANCE'\nEXISTING_DDL = 'EXISTING_DDL'\nCORTEX_RESPONSE = 'CORTEX_RESPONSE'\nMODEL_NAME = 'llama3.1-70b'\nTARGET_OBJECT_NAME = 'TARGET_OBJECT_NAME'\nTARGET_OBJECT_DOMAIN = 'TARGET_OBJECT_DOMAIN'\nCHANGE_DETECTED_AT = 'CHANGE_DETECTED_AT'\n\nBRONZE_TABLE = 'BRONZE_SALESFORCE_CUSTOMERS'\n\nst.title(\"LLM-based Schema Lineage Manager ðŸŽˆ\")\nst.write(\"Effortlessly propagate schema changes across your data lineage with AI\")\n\n\n# Initialize all session state variables\nif \"current_index\" not in st.session_state:\n    st.session_state.current_index = 0\nif \"success_message_shown\" not in st.session_state:\n    st.session_state.success_message_shown = False\nif \"auto_propagate_done\" not in st.session_state:\n    st.session_state.auto_propagate_done = False\nif \"manual_propagate_active\" not in st.session_state:\n    st.session_state.manual_propagate_active = False\nif \"dfs_order\" not in st.session_state:\n    st.session_state.dfs_order = None\nif \"current_dfs_index\" not in st.session_state:\n    st.session_state.current_dfs_index = 0\n\n# Function to visualize lineage path\ndef visualize_lineage_path(lineage_df):\n    # Sort by distance for correct path order\n    lineage_df = lineage_df.sort_values(by=DISTANCE)\n    \n    # Initialize paths dictionary to store each branch\n    paths = {}\n    \n    # Iterate through each row and group by source object name\n    for _, row in lineage_df.iterrows():\n        source_name = row[SOURCE_OBJECT_NAME]\n        target_name = row[TARGET_OBJECT_NAME]\n\n        # Check if source already exists as a key in paths dictionary\n        if source_name in paths:\n            # Append new target if this is a continuation of an existing path\n            paths[source_name].append(target_name)\n        else:\n            # Start a new path branch from this source\n            paths[source_name] = [target_name]\n    \n    # Generate the lineage paths in the form of strings\n    lineage_paths = []\n    for source, targets in paths.items():\n        path_string = f\"{source} --> {' --> '.join(targets)}\"\n        lineage_paths.append(path_string)\n    \n    # Join paths with a double newline to clearly separate each distinct path\n    return \"\\n\\n\".join(lineage_paths)\n\n\ndef fetch_schema_changes():\n    query = f\"SELECT * FROM {SCHEMA_CHANGE_LOG} ORDER BY {CHANGE_DETECTED_AT} DESC\"\n    return session.create_dataframe(session.sql(query).collect()).to_pandas()\n\n# Function to get lineage information for a selected table\ndef return_lineage_query_for_changed_table(changed_table):\n    lineage_query = f\"\"\"\n    SELECT\n        {DISTANCE},\n        {SOURCE_OBJECT_NAME},\n        {TARGET_OBJECT_NAME},\n        {TARGET_OBJECT_DOMAIN}\n    FROM TABLE (SNOWFLAKE.CORE.GET_LINEAGE('{DATABASE}.{SCHEMA}.{changed_table}', 'TABLE', 'DOWNSTREAM', 10))\n    WHERE SOURCE_STATUS = 'ACTIVE' AND TARGET_STATUS = 'ACTIVE';\n    \"\"\"\n    return lineage_query\n\n# Function to clean LLM response\ndef clean_ddl_response(ddl_response):\n    return re.sub(r'```', '', ddl_response).strip()\n\n# Function to create LLM prompt with schema change log details\ndef create_llm_prompt(existing_table_ddl, schema_change_log_df, upstream_table_name, target_table_name, mode='apply'):\n    # Convert schema change log information into a readable string format    \n    schema_change_log_info = str(schema_change_log_df[0])\n\n    if mode == 'apply':\n        prompt = f\"\"\"\n            This is the existing DDL for the target table `{target_table_name}`:\n\n            {existing_table_ddl}\n\n            Based on the schema changes detected in the upstream table `{upstream_table_name}`, shown below:\n\n            {schema_change_log_info}\n\n            Make the necessary modifications to the DDL for `{target_table_name}` to incorporate these changes from `{upstream_table_name}`. \n            Ensure that:\n            1. The structure and formatting of the original DDL is preserved, including any `WITH` clauses, transformations, or filters.\n            2. The newly added or modified columns are integrated into the DDL appropriately, reflecting only the specified changes.\n            3. Only the final SQL query is returned as plain textâ€”do not include explanations, comments, or extraneous characters.\n\n            Return only the SQL query with the updated structure in plain text.\n        \"\"\"\n    else:  # 'preview' mode for a SELECT preview query\n        prompt = f\"\"\"\n            This is the existing DDL for the target table `{target_table_name}`:\n\n            {existing_table_ddl}\n\n            Based on the schema changes detected in the upstream table `{upstream_table_name}`, shown below:\n\n            {schema_change_log_info}\n\n            Generate a `SELECT` query to preview the modified structure for `{target_table_name}`.\n            Ensure that:\n            1. The query mirrors the original DDL structure, incorporating any transformations or `WITH` clauses.\n            2. The new columns from `{upstream_table_name}` are included only as specified in the schema change log.\n            3. Only the final SQL query is returned as plain textâ€”do not include explanations, comments, or extraneous characters.\n\n            Return only the SQL query for the preview in plain text.\n        \"\"\"\n\n    return prompt\n\n\n\n# Generate modified DDL for preview table\ndef generate_preview_table_ddl(ddl_sql, preview_table_name=\"PREVIEW_LLM_TABLE\"):\n    modified_ddl = re.sub(r\"(create or replace dynamic table\\s+)(\\w+)\", f\"\\\\1{preview_table_name}\", ddl_sql, flags=re.IGNORECASE)\n    return modified_ddl\n\n# Function to apply changes automatically across all downstream tables\ndef auto_propagate_changes(lineage_df, upstream_table_name):\n    for index, row in lineage_df.iterrows():\n        target_table_name = row[TARGET_OBJECT_NAME]\n        target_table_domain = row[TARGET_OBJECT_DOMAIN]\n        \n        # Fetch existing DDL for the current downstream table\n        existing_table_ddl_query = f\"SELECT GET_DDL('{target_table_domain}', '{target_table_name}') AS {EXISTING_DDL}\"\n        existing_table_ddl_df = session.create_dataframe(session.sql(existing_table_ddl_query).collect()).to_pandas()\n        existing_table_ddl = existing_table_ddl_df[EXISTING_DDL].iloc[0]\n        \n        # Generate apply prompt\n        apply_prompt = create_llm_prompt(existing_table_ddl, schema_change_log_df, upstream_table_name, target_table_name, mode='apply')                       \n        \n        # Get the LLM-suggested DDL\n        apply_response = session.sql(f\"SELECT snowflake.cortex.complete('{MODEL_NAME}', $${apply_prompt}$$)\").collect()\n        new_ddl_suggestion = clean_ddl_response(apply_response[0][0])\n\n        # Apply the DDL directly\n        try:\n            session.sql(new_ddl_suggestion).collect()\n            st.success(f\"Applied DDL for {target_table_name}\")\n            time.sleep(2)  # Short pause to display success message\n        except Exception as e:\n            st.error(f\"Error applying DDL to {target_table_name}: {e}\")\n            break  # Stop further propagation if an error occurs\n\n# Load and display schema change log data\ndata = fetch_schema_changes()\nst.write(\"Schema Change Log:\")\ndata_container = st.empty()\ndata_container.dataframe(data)\n\nschema_change_log_df = session.sql(f\"SELECT * FROM {SCHEMA_CHANGE_LOG}\").collect()\n\n# Populate the selection list with unique table names\nschema_change_log = session.create_dataframe(session.sql(f\"SELECT * FROM {SCHEMA_CHANGE_LOG}\").collect()).to_pandas()\nchanged_table_list = list(schema_change_log[TABLE_NAME].unique())\nchanged_table_list.insert(0, 'Select Table')\nselected_source_object = st.selectbox('Which changed table do you want to review?', changed_table_list)\n\n@st.cache_data\ndef cache_lineage_df(selected_source_object):    \n    # Initialize lineage info\n    lineage_query = return_lineage_query_for_changed_table(selected_source_object)\n    lineage_df = session.sql(lineage_query).collect()\n\n    return lineage_df\n\n@st.cache_data\ndef cache_lineage_path(lineage_df):    \n\n    lineage_pandas_df = session.create_dataframe(lineage_df).to_pandas()\n    lineage_path = visualize_lineage_path(lineage_pandas_df)\n    \n    return lineage_path \n\n\n# Add these functions after your existing helper functions\n\ndef build_adjacency_list(lineage_df):\n    \"\"\"\n    Build an adjacency list representation of the lineage graph from the lineage dataframe.\n    \"\"\"\n    adj_list = defaultdict(list)\n    for _, row in lineage_df.iterrows():\n        source = row[SOURCE_OBJECT_NAME]\n        target = row[TARGET_OBJECT_NAME]\n        adj_list[source].append({\n            'table_name': target,\n            'domain': row[TARGET_OBJECT_DOMAIN],\n            'distance': row[DISTANCE]\n        })\n    return adj_list\n\ndef get_dfs_order(adj_list, start_table):\n    \"\"\"\n    Get the DFS traversal order of tables\n    \"\"\"\n    visited = set()\n    traversal_order = []\n    \n    def dfs(table):\n        if table not in visited:\n            visited.add(table)\n            for target in adj_list[table]:\n                traversal_order.append({\n                    'source': table,\n                    'target': target['table_name'],\n                    'domain': target['domain']\n                })\n                dfs(target['table_name'])\n    \n    dfs(start_table)\n    return traversal_order\n\n# Modified auto_propagate_changes function\ndef auto_propagate_changes(lineage_df, upstream_table_name):\n    # Convert lineage_df to pandas if it's not already\n    lineage_pandas_df = session.create_dataframe(lineage_df).to_pandas() if not isinstance(lineage_df, pd.DataFrame) else lineage_df\n    \n    # Build adjacency list and get DFS order\n    adj_list = build_adjacency_list(lineage_pandas_df)\n    dfs_order = get_dfs_order(adj_list, upstream_table_name)\n    \n    # Process each table in DFS order\n    for item in dfs_order:\n        target_table_name = item['target']\n        target_table_domain = item['domain']\n        source_table = item['source']\n        \n        # Fetch existing DDL for the current downstream table\n        existing_table_ddl_query = f\"SELECT GET_DDL('{target_table_domain}', '{target_table_name}') AS {EXISTING_DDL}\"\n        existing_table_ddl_df = session.create_dataframe(session.sql(existing_table_ddl_query).collect()).to_pandas()\n        existing_table_ddl = existing_table_ddl_df[EXISTING_DDL].iloc[0]\n        \n        # Generate apply prompt\n        apply_prompt = create_llm_prompt(existing_table_ddl, schema_change_log_df, source_table, target_table_name, mode='apply')\n        \n        # Get the LLM-suggested DDL\n        apply_response = session.sql(f\"SELECT snowflake.cortex.complete('{MODEL_NAME}', $${apply_prompt}$$)\").collect()\n        new_ddl_suggestion = clean_ddl_response(apply_response[0][0])\n        \n        # Apply the DDL directly\n        try:\n            session.sql(new_ddl_suggestion).collect()\n            st.success(f\"Applied DDL for {target_table_name}\")\n            time.sleep(2)  # Short pause to display success message\n        except Exception as e:\n            st.error(f\"Error applying DDL to {target_table_name}: {e}\")\n            break  # Stop further propagation if an error occurs\n\n# Initialize additional session state variables\nif \"dfs_order\" not in st.session_state:\n    st.session_state.dfs_order = None\nif \"current_dfs_index\" not in st.session_state:\n    st.session_state.current_dfs_index = 0\n\n# Update the main UI section where the buttons are defined\nif selected_source_object != 'Select Table':\n    st.write('You selected:', selected_source_object, '\\n')\n\n    # Initialize lineage info\n    st.write(\"_Processing Table's Lineage via Snowflake's Lineage Function..._\")\n    lineage_df = cache_lineage_df(selected_source_object)\n\n    \n    lineage, auto_propagation = st.columns(2)    \n    \n    # Option to display lineage path\n    if lineage.button(\"Show Lineage Path\"):        \n        lineage_path = cache_lineage_path(lineage_df)\n        st.write(\"Impacted Downstream Tables:\")\n        st.write(lineage_path)\n\n    # Button for automatic downstream propagation\n    if auto_propagation.button(\"Auto-Propagate Changes\"):\n        lineage_pandas_df = session.create_dataframe(lineage_df).to_pandas()\n        auto_propagate_changes(lineage_pandas_df, selected_source_object)\n        st.session_state.auto_propagate_done = True\n        st.write(\"All tables in the lineage have been processed.\")\n\n    # Button to start manual propagation\n    if st.button(\"Manually Propagate Changes\") or st.session_state.manual_propagate_active:\n        st.session_state.manual_propagate_active = True\n        \n        # Initialize DFS order if not already done\n        if st.session_state.dfs_order is None:\n            lineage_pandas_df = session.create_dataframe(lineage_df).to_pandas()\n            adj_list = build_adjacency_list(lineage_pandas_df)\n            st.session_state.dfs_order = get_dfs_order(adj_list, selected_source_object)\n            st.session_state.current_dfs_index = 0\n        \n        # Check if we still have tables to process\n        if st.session_state.current_dfs_index < len(st.session_state.dfs_order):\n            current_item = st.session_state.dfs_order[st.session_state.current_dfs_index]\n            target_table_name = current_item['target']\n            target_table_domain = current_item['domain']\n            source_table = current_item['source']\n            \n            st.write(f\"Processing: {target_table_name}\")\n\n            # Fetch existing DDL for the current downstream table\n            existing_table_ddl_query = f\"SELECT GET_DDL('{target_table_domain}', '{target_table_name}') AS {EXISTING_DDL}\"\n            existing_table_ddl_df = session.sql(existing_table_ddl_query).collect()\n            existing_table_ddl = existing_table_ddl_df[0][EXISTING_DDL]\n\n            # Generate preview and apply prompts\n            preview_prompt = create_llm_prompt(existing_table_ddl, schema_change_log_df, source_table, target_table_name, mode='preview')\n            apply_prompt = create_llm_prompt(existing_table_ddl, schema_change_log_df, source_table, target_table_name, mode='apply')\n\n            # LLM suggestions for DDL updates\n            apply_response = session.sql(f\"SELECT snowflake.cortex.complete('{MODEL_NAME}', $${apply_prompt}$$)\").collect()\n            new_ddl_suggestion = clean_ddl_response(apply_response[0][0])\n\n            # Show DDL comparison side by side\n            col1, col2 = st.columns(2)\n            with col1:\n                st.text_area(\"Existing DDL\", value=existing_table_ddl, height=300, key=f\"existing_ddl_{target_table_name}\")\n            with col2:\n                edited_sql = st.text_area(\"LLM Suggested New DDL\", value=new_ddl_suggestion, height=300, key=f\"suggested_ddl_{target_table_name}\")\n\n            preview_button, apply_button = st.columns(2)\n\n            # Preview button\n            if preview_button.button(\"Preview Changes\", key=f\"preview_{st.session_state.current_dfs_index}\"):\n                preview_table_sql = generate_preview_table_ddl(edited_sql)\n                try:\n                    session.sql(preview_table_sql).collect()\n                    st.write(\"Preview Results:\")\n                    st.write(session.sql(\"SELECT * FROM PREVIEW_LLM_TABLE\").collect())\n                except Exception as e:\n                    st.error(f\"Error executing preview: {e}\")\n                finally:\n                    session.sql(\"DROP TABLE IF EXISTS PREVIEW_LLM_TABLE\").collect()\n\n            # Apply changes and proceed to the next table\n            if apply_button.button(\"Apply Changes\", key=f\"apply_{st.session_state.current_dfs_index}\"):\n                try:\n                    session.sql(edited_sql).collect()\n                    st.success(f\"Applied DDL for {target_table_name}\")\n                    st.session_state.success_message_shown = True\n                except Exception as e:\n                    st.error(f\"Error applying DDL: {e}\")\n\n            # Automatically proceed to the next table after applying changes\n            if st.session_state.success_message_shown:\n                time.sleep(2)  # Short pause to show success message\n                st.session_state.success_message_shown = False\n                st.session_state.current_dfs_index += 1\n\n                # Rerun if there are more tables to process; else end propagation\n                if st.session_state.current_dfs_index < len(st.session_state.dfs_order):\n                    st.rerun()\n                else:\n                    st.session_state.manual_propagate_active = False\n                    st.session_state.dfs_order = None  # Reset DFS order\n                    st.write(\"All tables in the lineage have been processed.\")\n        else:\n            st.session_state.manual_propagate_active = False\n            st.session_state.dfs_order = None  # Reset DFS order\n            st.write(\"All tables in the lineage have been processed.\")",
   "execution_count": null,
   "outputs": []
  }
 ]
}