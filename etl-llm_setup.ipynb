{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "dknslyrfmtnvdiegez6v",
   "authorId": "1134732619951",
   "authorName": "ABLOCK",
   "authorEmail": "andy.block@snowflake.com",
   "sessionId": "f37d3844-0f16-4530-a39c-73ce70881d93",
   "lastEditTime": 1740622036644
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "collapsed": false
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5a981aba-b7d4-4398-bb54-dfe218687d2c",
   "metadata": {
    "name": "cell4",
    "collapsed": false
   },
   "source": "# SETUP"
  },
  {
   "cell_type": "code",
   "id": "78eb470e-079e-4db0-8b0b-452ee919790c",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "collapsed": false
   },
   "outputs": [],
   "source": "current_role = session.sql('select current_role()').collect()[0][0]\nif current_role == 'ACCOUNTADMIN':\n    current_role = 'ROLE100'\n\nrole_num = current_role.split('ROLE')[1]\n\ncurrent_db = session.sql('select current_database()').collect()[0][0]\ncurrent_schema = session.sql('select current_schema()').collect()[0][0]\ncurrent_wh = session.sql('select current_warehouse()').collect()[0][0]",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f42b597e-ff10-437e-95ee-dce38b0ec1ca",
   "metadata": {
    "name": "cell17",
    "collapsed": false
   },
   "source": "# 1. Overview\nSchema changes in upstream tables, like new fields from sources like Salesforce, must be carefully propagated to all downstream tables. Data Engineers manually tracking and updating each affected table is time-consuming and error-prone, often leading to broken pipelines and data inconsistencies. This guide leverages AI-powered automation to streamline schema propagation, ensuring accurate and consistent updates across data lineage, minimizing errors, and saving valuable time for data engineers.\n\n## Prerequisites\nFamiliarity with SQL and Snowflake\nBasic knowledge of data lineage concepts\nWhat You'll Build\nA powerful solution for automated schema propagation that combines Snowflake's processing capabilities with the intelligence of LLMs, enabling end-to-end lineage management. By the end of this guide, you'll have a framework that detects schema changes in upstream tables and ensures their propagation downstream with AI precision.\n\n## What You'll Need\nA Snowflake Account\nStreamlit in Snowflake\n\n## What You'll Learn\nHow to create an LLM-powered lineage manager that autonomously handles schema evolution across downstream tables\nLeveraging LLMs to automatically assess and adapt DDL changes, simplifying complex workflows\nUsing Snowflake tasks for continuous schema monitoring\nBuilding an intuitive UI with Streamlit for managing schema propagation"
  },
  {
   "cell_type": "markdown",
   "id": "eb9350dc-02a9-409a-ae0f-14622ea27bb1",
   "metadata": {
    "name": "cell18",
    "collapsed": false
   },
   "source": "# 2. Application Architecture\nThis solution leverages the intelligence of LLMs to dynamically analyze and respond to schema changes, creating a seamless flow of information across your data pipeline. The architecture of this application includes:\n\n1. **Upstream and Downstream Tables in Snowflake**: A series of tables that form a lineage, where updates in upstream tables must cascade downstream.\n2. **LLM-Powered Schema Analysis**: The core engine uses LLMs to generate and apply appropriate DDL (Data Definition Language) modifications, ensuring the consistency of schema changes across all affected tables.\n3. **Schema Change Monitor**: A Snowflake task that continuously tracks schema alterations in upstream tables and logs any detected changes.\n4. **Streamlit-based UI**: Provides an accessible, intuitive interface to monitor and manage schema propagation, showcasing LLM-suggested DDL changes for review and approval.\n5. **Automated Propagation Workflow**: Utilizes a directed graph traversal algorithm (DFS) to ensure the orderly propagation of changes across the entire data pipeline.\n\n## Architecture Diagram\n\n[Click here!](https://quickstarts.snowflake.com/guide/schema_lineage_auto_propagation_llm/index.html?index=..%2F..index#1)"
  },
  {
   "cell_type": "markdown",
   "id": "8e79d672-4e25-4af3-a411-b90002fd2a7e",
   "metadata": {
    "name": "cell6",
    "collapsed": false
   },
   "source": "# 3. Initial (Dynamic) Tables\nThis section includes the setup of the initial tables, which represent different levels in the data lineage (Bronze, Silver, Gold, etc.) using Dynamic Tables. We also create a baseline schema to detect future changes.\n\nThe example below has this medallion structure:\n\nBronze -> Silver -> Gold -> Platinum -> Gold2"
  },
  {
   "cell_type": "code",
   "id": "16348520-843c-4dea-ade4-5d53efe4d265",
   "metadata": {
    "language": "sql",
    "name": "cell7"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE bronze_salesforce_customers (\n    customer_id NUMBER(38,0),\n    customer_name VARCHAR(16777216),\n    customer_region VARCHAR(16777216),\n    created_date DATE    \n);\n\nINSERT INTO bronze_salesforce_customers (customer_id, customer_name, customer_region, created_date)\nVALUES\n    (101, 'Acme Corp', 'North', '2022-01-01'),\n    (102, 'Beta LLC', 'South', '2021-06-15'),\n    (103, 'Gamma Inc', 'East', '2023-03-20'),\n    (104, 'Delta Co', 'West', '2022-09-10'),\n    (105, 'Epsilon Ltd', 'North', '2021-12-30');",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "source": "session.sql(f\"\"\"\nCREATE OR REPLACE DYNAMIC TABLE silver_customers\nWAREHOUSE = {current_wh}\nLAG = '1 day'\nAS\nWITH base AS (\n    SELECT\n        customer_id,\n        customer_name,\n        customer_region,\n        created_date\n    FROM bronze_salesforce_customers\n)\nSELECT\n    customer_id,\n    customer_name,\n    UPPER(customer_region) AS region_standardized,  -- Standardize region to uppercase\n    DATEDIFF('day', created_date, CURRENT_DATE) AS account_age_days  -- Calculate account age in days\nFROM base\nWHERE created_date IS NOT NULL;\n\"\"\").collect()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "dcf8e7e9-d509-4cb2-a9c9-7cd3ad6472fb",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": "session.sql(f\"\"\"\nCREATE OR REPLACE DYNAMIC TABLE gold_customer_analytics\nWAREHOUSE = {current_wh}\nLAG = '1 day'\nAS\nWITH base AS (\n    SELECT\n        customer_id,\n        customer_name,\n        region_standardized,\n        account_age_days\n    FROM silver_customers\n)\nSELECT\n    customer_id,\n    customer_name,\n    region_standardized,\n    account_age_days,\n    \n    -- Derived field for customer lifetime category\n    CASE \n        WHEN account_age_days < 365 THEN 'New'\n        WHEN account_age_days BETWEEN 365 AND 730 THEN 'Loyal'\n        ELSE 'Long-Term'\n    END AS customer_lifetime_category  -- New derived column for analytics\nFROM base;\n\"\"\").collect()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "67cdb9b9-c119-4d37-8198-ae72548abbe1",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": "session.sql(f\"\"\"\nCREATE OR REPLACE DYNAMIC TABLE gold_customer_analytics_v2\nWAREHOUSE = {current_wh}\nLAG = '1 day'\nAS\nWITH base AS (\n    SELECT\n        customer_id,\n        customer_name,\n        region_standardized,\n        account_age_days\n    FROM silver_customers\n)\nSELECT\n    customer_id,\n    customer_name,\n    region_standardized,\n    account_age_days,\n    \n    -- New field for customer engagement level based on account age\n    CASE \n        WHEN account_age_days < 180 THEN 'Newly Engaged'\n        WHEN account_age_days BETWEEN 180 AND 540 THEN 'Moderately Engaged'\n        ELSE 'Highly Engaged'\n    END AS customer_engagement_level,\n    \n    -- Simple classification based on region for geographic grouping\n    CASE\n        WHEN region_standardized = 'NORTH' OR region_standardized = 'SOUTH' THEN 'Domestic'\n        WHEN region_standardized = 'EAST' OR region_standardized = 'WEST' THEN 'International'\n        ELSE 'Unknown'\n    END AS geographic_category\n\nFROM base;\n\"\"\").collect()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "139eaf2c-4fb6-477a-9d54-eddc681bfe5e",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": "session.sql(f\"\"\"\nCREATE OR REPLACE DYNAMIC TABLE platinum_customer_insights\nWAREHOUSE = {current_wh}\nLAG = '1 day'\nAS\nWITH base AS (\n    SELECT\n        customer_id,\n        customer_name,\n        region_standardized,\n        account_age_days,\n        customer_lifetime_category\n    FROM gold_customer_analytics\n)\nSELECT\n    customer_id,\n    customer_name,\n    region_standardized,\n    account_age_days,\n    customer_lifetime_category,\n    \n    -- Derived field to indicate customer loyalty status\n    CASE \n        WHEN customer_lifetime_category = 'Long-Term' THEN 'High Loyalty'\n        WHEN customer_lifetime_category = 'Loyal' THEN 'Medium Loyalty'\n        ELSE 'Low Loyalty'\n    END AS customer_loyalty_status,\n    \n    -- Segmenting customers based on region for targeted marketing insights\n    CASE \n        WHEN region_standardized = 'NORTH' THEN 'Northern Market'\n        WHEN region_standardized = 'SOUTH' THEN 'Southern Market'\n        WHEN region_standardized = 'EAST' THEN 'Eastern Market'\n        WHEN region_standardized = 'WEST' THEN 'Western Market'\n        ELSE 'Other Market'\n    END AS market_segment,\n    \n    -- Assign a discount eligibility flag based on customer lifetime category and loyalty\n    CASE \n        WHEN customer_lifetime_category = 'Long-Term' OR customer_loyalty_status = 'High Loyalty' THEN 'Eligible'\n        ELSE 'Not Eligible'\n    END AS discount_eligibility_flag,\n\n    -- Customer engagement level based on age and loyalty, for example purposes\n    CASE\n        WHEN account_age_days > 730 AND customer_loyalty_status = 'High Loyalty' THEN 'Highly Engaged'\n        WHEN account_age_days BETWEEN 365 AND 730 THEN 'Moderately Engaged'\n        ELSE 'Newly Engaged'\n    END AS engagement_level\n\nFROM base;\n\"\"\").collect()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2f6ab45e-76b1-4852-ad1d-172a18f7d95a",
   "metadata": {
    "name": "cell11",
    "collapsed": false
   },
   "source": "# 4. Monitoring Task\nIn this part, you'll create a Snowflake task to continuously monitor schema changes in upstream tables. When a change is detected, the task logs it in a schema change log and updates the schema baseline for consistency."
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "sql",
    "name": "cell3"
   },
   "source": "CREATE OR REPLACE TABLE schema_baseline (  \n    table_name STRING,\n    column_name STRING,\n    data_type STRING\n);\n\nCREATE OR REPLACE TABLE schema_change_log (\n    change_detected_at TIMESTAMP,\n    table_name STRING,\n    column_name STRING,\n    data_type STRING,\n    change_type STRING\n);",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "52239fdc-d4c5-4f8f-8ee8-c22fc0425b07",
   "metadata": {
    "language": "python",
    "name": "cell12",
    "collapsed": false
   },
   "outputs": [],
   "source": "session.sql(f\"\"\"\nCREATE OR REPLACE TASK schema_change_monitor\nWAREHOUSE = {current_wh}\nSCHEDULE = 'USING CRON * * * * * UTC'  -- Runs every minute\nAS\nBEGIN\n    INSERT INTO schema_change_log (change_detected_at, table_name, column_name, data_type, change_type)\n    SELECT \n        CURRENT_TIMESTAMP AS change_detected_at,\n        table_name,\n        column_name,\n        data_type,\n        'ADDED' AS change_type\n    FROM INFORMATION_SCHEMA.COLUMNS\n    WHERE table_schema = '{current_schema}'\n      AND table_catalog = '{current_db}'\n      AND column_name NOT IN (SELECT column_name FROM schema_baseline)\n      AND table_name != 'SCHEMA_CHANGE_LOG'\n    ORDER BY TABLE_NAME;\n\n    INSERT INTO schema_baseline (table_name, column_name, data_type)\n    SELECT table_name, column_name, data_type\n    FROM INFORMATION_SCHEMA.COLUMNS\n    WHERE table_schema = '{current_schema}'\n      AND table_catalog = '{current_db}'\n      AND (table_name, column_name) NOT IN (SELECT table_name, column_name FROM schema_baseline)\n    ORDER BY TABLE_NAME;\nEND;\n\"\"\").collect()\n\nsession.sql('ALTER TASK schema_change_monitor RESUME;').collect()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4c9c0519-7f32-4712-9c68-3d2ed1e8fb3f",
   "metadata": {
    "name": "cell13",
    "collapsed": false
   },
   "source": "# 5. Upstream Schema Changes\nIn this part, simulate a schema change in the upstream table by adding a new column. This change will automatically be detected and logged, triggering downstream updates.\n\nCurrently, the unaltered upstream table looks like this:\n\n![Current Bronze Customers Table](https://quickstarts.snowflake.com/guide/schema_lineage_auto_propagation_llm/img/99a3ddd62fde6af.png)"
  },
  {
   "cell_type": "code",
   "id": "6a0c915f-c0d7-4431-976b-0084b8d0d604",
   "metadata": {
    "language": "sql",
    "name": "cell14"
   },
   "outputs": [],
   "source": "select * from bronze_salesforce_customers;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "19869283-cf44-4040-9400-ae0c7f1efa69",
   "metadata": {
    "language": "sql",
    "name": "cell15"
   },
   "outputs": [],
   "source": "-- Alter table to add a new column\nALTER TABLE bronze_salesforce_customers \nADD COLUMN customer_segment VARCHAR(16777216);\n\n-- Set initial values for existing records\nUPDATE bronze_salesforce_customers\nSET customer_segment = CASE \n    WHEN customer_region = 'North' THEN 'Premium'\n    WHEN customer_region = 'South' THEN 'Basic'\n    WHEN customer_region = 'East' THEN 'Standard'\n    WHEN customer_region = 'West' THEN 'Enterprise'\n    ELSE 'Unknown'\nEND;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bc18526b-2a1f-49c2-bec2-3845839a783f",
   "metadata": {
    "language": "sql",
    "name": "cell16"
   },
   "outputs": [],
   "source": "select * from bronze_salesforce_customers;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f009ec29-1e21-49b5-81ba-eeaeb2bc7d00",
   "metadata": {
    "name": "cell19",
    "collapsed": false
   },
   "source": "# 6. Snowflake in Streamlit Code\nWith the groundwork laid, you're ready to integrate the Streamlit-based UI for hands-on control of schema propagation. This UI, backed by LLMs, allows you to manage schema changes in a user-friendly environment. Users will be able to visualize lineage, apply or preview LLM-suggested DDL changes, and monitor the entire propagation process.\n\n"
  }
 ]
}